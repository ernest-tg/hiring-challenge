{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa323fc0",
   "metadata": {},
   "source": [
    "## Summary\n",
    "* No classification error found.\n",
    "* Some videos are duplicated in the 'noFights' folder, we remove them from the dataset.\n",
    "* Some properties (unrelated to the presence of a fight) are different between the videos of fights and others: height of the images, frame-per-seconds, frame count, RGB means and variance, encoding algorithm. We will need to be careful to avoid a _[Clever Hans effect](https://en.wikipedia.org/wiki/Clever_Hans#The_Clever_Hans_effect)_ .\n",
    "* Some videos are very similar (e.g. consecutive clips of a fight). If a model is trained on some clips from a fight and evaluated on other clips of the same fight, it might output correct classification based on the people's clothes. This would not generalize to other videos. We will design train/val splits avoiding this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f5ca43",
   "metadata": {},
   "source": [
    "## Todo\n",
    "\n",
    "* Import project_root instead of hardcoding it\n",
    "* Clean up the \"properties\" part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c979a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the videos\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from fight_classifier import DATASET_DIR\n",
    "fights_dir = DATASET_DIR / \"fights\"\n",
    "no_fights_dir = DATASET_DIR / \"noFights\"\n",
    "\n",
    "fights_names = os.listdir(fights_dir)\n",
    "no_fights_names = os.listdir(no_fights_dir)\n",
    "\n",
    "fights_paths = [fights_dir / name for name in fights_names]\n",
    "no_fights_paths = [no_fights_dir / name for name in no_fights_names]\n",
    "print(f'{len(fights_paths)} fight videos, {len(no_fights_paths)} no-fight videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c64be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect duplicates\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Mapping\n",
    "\n",
    "import tqdm\n",
    "\n",
    "unique_fights_paths = []\n",
    "unique_no_fights_paths = []\n",
    "hash_to_paths: Mapping[int, List[str]] = defaultdict(list)\n",
    "    \n",
    "for path in tqdm.tqdm(fights_paths):\n",
    "    path_str = str(path)\n",
    "    video = skvideo.io.vread(path_str)\n",
    "    video_hash = hash(video.tobytes())\n",
    "    if video_hash not in hash_to_paths:\n",
    "        unique_fights_paths.append(path)\n",
    "    hash_to_paths[video_hash].append(path_str)\n",
    "    \n",
    "for path in tqdm.tqdm(no_fights_paths):\n",
    "    path_str = str(path)\n",
    "    video = skvideo.io.vread(path_str)\n",
    "    video_hash = hash(video.tobytes())\n",
    "    if video_hash not in hash_to_paths:\n",
    "        unique_no_fights_paths.append(path)\n",
    "    hash_to_paths[video_hash].append(path_str)\n",
    "\n",
    "duplicates = {\n",
    "    video_hash: paths \n",
    "    for video_hash, paths in hash_to_paths.items()\n",
    "    if len(paths) != 1\n",
    "}\n",
    "\n",
    "print(f'Duplicates, {duplicates}\\n')\n",
    "print(\n",
    "    f'{len(unique_fights_paths)} unique fight videos, '\n",
    "    f'{len(unique_no_fights_paths)} unique no-fight videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2c5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "videos_dicts = []\n",
    "\n",
    "# We sort the videos by index, to make it easier to manually fill\n",
    "# the \"coarse_category\" and \"fine_category\" columns\n",
    "fights_re = re.compile('.*/newfi([0-9]+)')\n",
    "sorted_fights_paths = sorted(\n",
    "    unique_fights_paths, \n",
    "    key=lambda p: int(fights_re.match(str(p)).group(1)))\n",
    "\n",
    "no_fights_re = re.compile('.*/([0-9]+)')\n",
    "\n",
    "sorted_no_fights_paths = sorted(\n",
    "    unique_no_fights_paths,\n",
    "    key=lambda p: int(no_fights_re.match(str(p)).group(1)))\n",
    "\n",
    "for fight_path in sorted_fights_paths:\n",
    "    fight_dict = {\n",
    "        'video_path': str(fight_path.relative_to(DATASET_DIR)),\n",
    "        'is_fight': True,\n",
    "        'coarse_category': None,\n",
    "        'fine_category': None,\n",
    "    }\n",
    "    videos_dicts.append(fight_dict)\n",
    "for fight_path in sorted_no_fights_paths:\n",
    "    fight_dict = {\n",
    "        'video_path': str(fight_path.relative_to(DATASET_DIR)),\n",
    "        'is_fight': False,\n",
    "        'coarse_category': None,\n",
    "        'fine_category': None,\n",
    "    }\n",
    "    videos_dicts.append(fight_dict)\n",
    "videos_df = pd.DataFrame(videos_dicts)\n",
    "videos_df.to_csv(str(DATASET_DIR / 'empty_videos.csv'))\n",
    "videos_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbf9100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a pandas.DataFrame of the videos with some properties\n",
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skvideo.io\n",
    "import tqdm\n",
    "\n",
    "def video_path_to_np_old(video_path) -> Dict[str, Any]:\n",
    "    \"\"\"Returns basic video properties\"\"\"\n",
    "    capture = cv2.VideoCapture(str(video_path))\n",
    "    prop_dict = {\n",
    "        \"CV_CAP_PROP_FRAME_WIDTH\" : capture.get(cv2.CAP_PROP_FRAME_WIDTH),\n",
    "        \"CV_CAP_PROP_FRAME_HEIGHT\" : capture.get(cv2.CAP_PROP_FRAME_HEIGHT),\n",
    "        \"CAP_PROP_FPS\" : capture.get(cv2.CAP_PROP_FPS),\n",
    "        \"CAP_PROP_POS_MSEC\" : capture.get(cv2.CAP_PROP_POS_MSEC),\n",
    "        \"CAP_PROP_FRAME_COUNT\" : capture.get(cv2.CAP_PROP_FRAME_COUNT),\n",
    "        \"CAP_PROP_BRIGHTNESS\" : capture.get(cv2.CAP_PROP_BRIGHTNESS),\n",
    "        \"CAP_PROP_CONTRAST\" : capture.get(cv2.CAP_PROP_CONTRAST),\n",
    "        \"CAP_PROP_SATURATION\" : capture.get(cv2.CAP_PROP_SATURATION),\n",
    "        \"CAP_PROP_HUE\" : capture.get(cv2.CAP_PROP_HUE),\n",
    "        \"CAP_PROP_GAIN\" : capture.get(cv2.CAP_PROP_GAIN),\n",
    "        \"CAP_PROP_CONVERT_RGB\" : capture.get(cv2.CAP_PROP_CONVERT_RGB),        \n",
    "    }\n",
    "    capture.release()\n",
    "    return  prop_dict\n",
    "\n",
    "# Properties of each unique video\n",
    "prop_dicts: List[Dict[str, Any]] = []\n",
    "\n",
    "paths_with_gt = [(path, True) for path in fights_paths] + [(path, False) for path in no_fights_paths]\n",
    "for path, is_fight in tqdm.tqdm(paths_with_gt):\n",
    "    prop_dict = video_path_to_np_old(path)\n",
    "    prop_dict['is_fight'] = is_fight\n",
    "\n",
    "    video = skvideo.io.vread(str(path))\n",
    "    \n",
    "\n",
    "    if len(videos_hashes[video_hash]) > 1:\n",
    "        # Since we'll remove the duplicates, we don't want to count their properties twice\n",
    "        continue\n",
    "    \n",
    "    # Basic statistics on the video RGB values\n",
    "    r_mean, g_mean, b_mean = np.mean(video, axis=(0, 1, 2))\n",
    "    r_std, g_std, b_std = np.std(video, axis=(0, 1, 2))\n",
    "    prop_dict['r_mean'] = r_mean\n",
    "    prop_dict['g_mean'] = g_mean\n",
    "    prop_dict['b_mean'] = b_mean\n",
    "    prop_dict['r_std'] = r_std\n",
    "    prop_dict['g_std'] = g_std\n",
    "    prop_dict['b_std'] = b_std\n",
    "    prop_dict['brightness'] = np.mean((r_mean, g_mean, b_mean))\n",
    "    \n",
    "    prop_dicts.append(prop_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0943fa36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee7c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(videos_hashes.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fbd84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "props_df = pd.DataFrame(prop_dicts)\n",
    "informative_columns = []\n",
    "for column in props_df.columns:\n",
    "    unique_values = props_df[column].unique()\n",
    "    if len(unique_values) == 1 or column == 'is_fight':\n",
    "        continue\n",
    "    informative_columns.append(column)\n",
    "    print(\"\\n\", column)\n",
    "    props_df[column].hist(by=props_df['is_fight'])\n",
    "    plt.show()\n",
    "print(\"informative_columns \", informative_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7694ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "p = Path(\"/try/this_{}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce1cea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.format('hey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c5d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7da2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.replace('{}', '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af25be43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f698461f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbf212f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aviva",
   "language": "python",
   "name": "aviva"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
